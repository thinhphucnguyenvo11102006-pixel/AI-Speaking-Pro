import os
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import RedirectResponse
import google.generativeai as genai
from groq import Groq

# --- 1. C·∫§U H√åNH API (Th√¥ng minh h∆°n) ---
# Th·ª≠ load file .env n·∫øu ƒëang ch·∫°y tr√™n m√°y t√≠nh (c·∫ßn c√†i: pip install python-dotenv)
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ ƒê√£ n·∫°p c·∫•u h√¨nh t·ª´ file .env (Ch·∫ø ƒë·ªô Local)")
except:
    print("‚ÑπÔ∏è ƒêang ch·∫°y tr√™n Cloud ho·∫∑c kh√¥ng c√≥ python-dotenv")

# L·∫•y Key
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

# Kh·ªüi t·∫°o bi·∫øn to√†n c·ª•c
groq_client = None
model = None

# Ki·ªÉm tra Key ngay l·∫≠p t·ª©c
if not GROQ_API_KEY:
    print("‚ùå L·ªñI NGHI√äM TR·ªåNG: Thi·∫øu GROQ_API_KEY! App s·∫Ω kh√¥ng nghe ƒë∆∞·ª£c.")
if not GOOGLE_API_KEY:
    print("‚ùå L·ªñI NGHI√äM TR·ªåNG: Thi·∫øu GOOGLE_API_KEY! App s·∫Ω kh√¥ng tr·∫£ l·ªùi ƒë∆∞·ª£c.")

try:
    if GROQ_API_KEY:
        groq_client = Groq(api_key=GROQ_API_KEY)
        print("‚úÖ ƒê√£ k·∫øt n·ªëi Groq th√†nh c√¥ng.")
    
    if GOOGLE_API_KEY:
        genai.configure(api_key=GOOGLE_API_KEY)
        # Gi·ªØ nguy√™n model 2.5 theo √Ω b·∫°n (nh∆∞ng khuy·∫øn c√°o l√† n√≥ c√≥ th·ªÉ g√¢y l·ªói Error)
        model = genai.GenerativeModel('gemini-2.5-flash') 
        print("‚úÖ ƒê√£ c·∫•u h√¨nh Gemini th√†nh c√¥ng.")
        
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o Client: {e}")

# --- 2. KH·ªûI T·∫†O SERVER ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return RedirectResponse(url="/static/index.html")

app.mount("/static", StaticFiles(directory="static", html=True), name="static")

# --- 3. LOGIC X·ª¨ L√ù (C√≥ in log chi ti·∫øt) ---

def whisper_stt(audio_bytes):
    # Ki·ªÉm tra xem Client c√≥ s·ªëng kh√¥ng
    if not groq_client:
        print("‚ùå L·ªói: Groq Client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o (Do thi·∫øu Key).")
        return None

    try:
        print(f"üé§ ƒêang g·ª≠i {len(audio_bytes)} bytes l√™n Groq...", flush=True)
        return groq_client.audio.transcriptions.create(
            file=("input.webm", audio_bytes), 
            model="whisper-large-v3", 
            response_format="text", 
            language="en")
    except Exception as e:
        print(f"‚ùå L·ªói Whisper (API tr·∫£ v·ªÅ l·ªói): {e}", flush=True)
        return None

def repair_transcription(raw_text):
    if not model: return raw_text
    try:
        prompt = f"Act as a Contextual Corrector. Raw: '{raw_text}'. Fix machine errors silently. Flag pronunciation errors with [PRONUNCIATION ERROR: X->Y]. Output final text only."
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Repair: {e}")
        return raw_text

def get_examiner_response(history, user_input):
    if not model: return "Error ||| System API Key missing."
    
    system = "You are an IELTS Examiner. Format: **Band: [Score]** üìù [Feedback] ||| [Next Question]"
    prompt = f"{system}\nHISTORY:\n{history}\nUSER: {user_input}"
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"‚ùå L·ªñI GEMINI: {e}")
        return f"Error ({str(e)}) ||| I cannot connect to the brain right now."

@app.post("/process-audio")
async def process_audio(file: UploadFile = File(...), history_context: str = Form("")):
    # 1. ƒê·ªçc file
    audio_bytes = await file.read()
    print(f"üì© Server nh·∫≠n file: {len(audio_bytes)} bytes", flush=True)
    
    # Check file r·ªóng
    if len(audio_bytes) < 100:
        print("‚ö†Ô∏è File qu√° nh·ªè -> L·ªói Mic ph√≠a Client")
        return {"user_text_analyzed": "...", "examiner_question": "Microphone error: File is empty."}

    # 2. X·ª≠ l√Ω
    raw_text = whisper_stt(audio_bytes)
    
    if not raw_text: 
        print("‚ö†Ô∏è Whisper tr·∫£ v·ªÅ None -> Kh√¥ng nghe ƒë∆∞·ª£c g√¨.")
        return {"user_text_analyzed": "...", "examiner_question": "I didn't hear anything. Please check the Server Logs."}
    
    print(f"üó£Ô∏è Nghe ƒë∆∞·ª£c: {raw_text}", flush=True)

    analyzed_text = repair_transcription(raw_text)
    full_reply = get_examiner_response(history_context, analyzed_text)
    
    feedback = ""
    question = full_reply
    if "|||" in full_reply:
        parts = full_reply.split("|||")
        feedback = parts[0].strip()
        question = parts[1].strip() if len(parts) > 1 else ""

    return {
        "user_text_analyzed": analyzed_text,
        "examiner_feedback": feedback,
        "examiner_question": question
    }
